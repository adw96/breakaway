<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Amy Willis" />

<meta name="date" content="2021-10-01" />

<title>Getting started with breakaway</title>

<style type="text/css">
a.anchor-section {margin-left: 10px; visibility: hidden; color: inherit;}
a.anchor-section::before {content: '#';}
.hasAnchor:hover a.anchor-section {visibility: visible;}
</style>
<script>// Anchor sections v1.0 written by Atsushi Yasumoto on Oct 3rd, 2020.
document.addEventListener('DOMContentLoaded', function() {
  // Do nothing if AnchorJS is used
  if (typeof window.anchors === 'object' && anchors.hasOwnProperty('hasAnchorJSLink')) {
    return;
  }

  const h = document.querySelectorAll('h1, h2, h3, h4, h5, h6');

  // Do nothing if sections are already anchored
  if (Array.from(h).some(x => x.classList.contains('hasAnchor'))) {
    return null;
  }

  // Use section id when pandoc runs with --section-divs
  const section_id = function(x) {
    return ((x.classList.contains('section') || (x.tagName === 'SECTION'))
            ? x.id : '');
  };

  // Add anchors
  h.forEach(function(x) {
    const id = x.id || section_id(x.parentElement);
    if (id === '') {
      return null;
    }
    let anchor = document.createElement('a');
    anchor.href = '#' + id;
    anchor.classList = ['anchor-section'];
    x.classList.add('hasAnchor');
    x.appendChild(anchor);
  });
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Getting started with breakaway</h1>
<h4 class="author">Amy Willis</h4>
<h4 class="date">2021-10-01</h4>



<p><code>breakaway</code> is a package for species richness estimation and modelling. As the package has grown and users have requested more functionality, it contains some basic generalisations of the statistical philosophy that underpins <code>breakaway</code> to the general alpha diversity case. Because of the flexibility of the modelling strategies, most users of breakaway are microbial ecologists with very large OTU tables, however, nothing should exclude a macroecologist from using the same tools. If you have a macroecology dataset and want to use this package, I would love to hear from you so please feel free to contact me (email or via Github’s Issues/Projects infrastructure).</p>
<div id="vignette-info" class="section level2">
<h2>Vignette Info</h2>
<p>This vignette will lead you through</p>
<ul>
<li>loading in your data and covariate information</li>
<li>creating frequency tables</li>
<li>using <code>breakaway</code> to estimate species richness</li>
<li>using the objective bayes methods to estimate species richness</li>
<li>estimating various alpha diversity indices and providing a very basic resample-based method for ascribing variability to them</li>
<li>using <code>betta</code> to model changes in alpha diversity with covariates</li>
</ul>
<p>If there is something that you would like explained please feel free to request it!</p>
</div>
<div id="loading-the-package-and-data" class="section level2">
<h2>Loading the package and data</h2>
<p>Download the latest version of the package from github.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">library</span>(breakaway)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw">data</span>(toy_otu_table)</a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="kw">data</span>(toy_metadata)</a>
<a class="sourceLine" id="cb1-4" data-line-number="4"></a>
<a class="sourceLine" id="cb1-5" data-line-number="5"><span class="co">## For historical reasons we're going to call them:</span></a>
<a class="sourceLine" id="cb1-6" data-line-number="6">otu_data &lt;-<span class="st"> </span>toy_otu_table</a>
<a class="sourceLine" id="cb1-7" data-line-number="7">meta_data &lt;-<span class="st"> </span>toy_metadata</a>
<a class="sourceLine" id="cb1-8" data-line-number="8"><span class="kw">head</span>(meta_data)</a></code></pre></div>
<pre><code>##         Years bloom2 Period     Site
## Sample1  2008     no Spring Littoral
## Sample2  2008     no Spring  Pelagic
## Sample3  2008     no Spring  Pelagic
## Sample4  2008     no Summer  Pelagic
## Sample5  2007     no Summer Littoral
## Sample6  2007     no Summer  Pelagic</code></pre>
<p>It is important that the column names of the OTU table is the same as the rownames of the covariate information. Remember to reorder them if they don’t match! You can check this with</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="kw">head</span>(<span class="kw">colnames</span>(otu_data) <span class="op">==</span><span class="st"> </span><span class="kw">rownames</span>(meta_data))</a></code></pre></div>
<pre><code>## [1] TRUE TRUE TRUE TRUE TRUE TRUE</code></pre>
</div>
<div id="creating-frequency-tables" class="section level2">
<h2>Creating frequency tables</h2>
<p>We’re now going to “collapse” the otu_data’s columns (samples) into frequency tables. Frequency tables…</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1">frequencytablelist &lt;-<span class="st"> </span><span class="kw">build_frequency_count_tables</span>(otu_data)</a>
<a class="sourceLine" id="cb5-2" data-line-number="2"><span class="kw">head</span>(frequencytablelist[[<span class="dv">63</span>]])</a></code></pre></div>
<pre><code>##   index frequency
## 1     1        35
## 2     2        22
## 3     3        15
## 4     4        17
## 5     5        11
## 6     6        10</code></pre>
<p>Interpretation: In this sample, there were 57 different species observed only once (singletons), 25 different species observed only twice, …, 1 species observed 171 times.</p>
</div>
<div id="estimating-species-richness" class="section level2">
<h2>Estimating species richness</h2>
<p>Let’s run breakaway on the first frequency count table</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="kw">breakaway</span>(frequencytablelist[[<span class="dv">1</span>]])</a></code></pre></div>
<pre><code>## Estimate of richness from method breakaway:
##   Estimate is 359
##  with standard error 325.81
##   Confidence interval: (258, 18180)</code></pre>
<p>You should get some output to screen, including your estimate &amp; s.e., and a plot of the fits to the ratios. Note that it is not a fit to the frequencies, it is a fit to the ratios of frequencies. You would never need to include this type of plot in one of your papers. It is solely for you to check for model misspecification. What’s model misspecification? If the black diamonds don’t remotely follow the pattern of the white circles, that’s model misspecification.</p>
<p>Sometimes, breakaway’s usual procedure doesn’t work, that is, it gives a negative estimate, which is of course silly. In that case, breakaway returns a different model’s result. It’s called the WLRM. There isn’t a picture. Here is an example of a case where breakaway returns the WLRM.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="kw">breakaway</span>(frequencytablelist[[<span class="dv">60</span>]])</a></code></pre></div>
<pre><code>## Estimate of richness from method breakaway:
##   Estimate is 414
##  with standard error 17.53
##   Confidence interval: (373, 1111)</code></pre>
<p>breakaway can defer to the WLRM for several reasons. Perhaps there are too many singletons. Perhaps there isn’t a long enough tail. Perhaps there is false diversity. In this case, there was probably not enough data. Let’s see if this failure was sensitive to the singleton count by running breakaway_nof1. This requires no singleton count (implicit is that the singleton count was erroneous) and predicts it from the other frequencies.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="kw">breakaway_nof1</span>(frequencytablelist[[<span class="dv">60</span>]][<span class="op">-</span><span class="dv">1</span>,])</a></code></pre></div>
<pre><code>## Estimate of richness from method PoissonModel:
##   Estimate is 223
##  with standard error 0.08
##   Confidence interval: (223, 223)</code></pre>
<p>The reference for this method: Willis, A. (2016). Species richness estimation with high diversity but spurious singletons.</p>
<p>breakaway_nof1 is an exploratory tool for assessing sensitivity of breakaway to the singleton count. You should not use it for diversity estimation – only diversity <em>exploration</em> :)</p>
<p>Let’s move on to looking at the Objective Bayes procedures of Kathryn Barger. It’s the latest and greatest in diversity estimation!</p>
<p>There are 4 different types of objective bayes estimates, due to 4 different models. If you have time play with all of them! For now we are just going to look at the negative binomial.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1"><span class="co">## Uncomment this at home: just takes a while for compiling</span></a>
<a class="sourceLine" id="cb13-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb13-3" data-line-number="3"><span class="co">#objective_bayes_negbin(frequencytablelist[[1]], plot = F)</span></a>
<a class="sourceLine" id="cb13-4" data-line-number="4"></a>
<a class="sourceLine" id="cb13-5" data-line-number="5"><span class="co">### Play with these later</span></a>
<a class="sourceLine" id="cb13-6" data-line-number="6"><span class="co">#objective_bayes_poisson(frequencytablelist[[60]])$results</span></a>
<a class="sourceLine" id="cb13-7" data-line-number="7"><span class="co">#objective_bayes_geometric(frequencytablelist[[60]])$results</span></a>
<a class="sourceLine" id="cb13-8" data-line-number="8"><span class="co">#objective_bayes_mixedgeo(frequencytablelist[[60]])$results</span></a></code></pre></div>
<p>That’s a lot of information! Bayesians are very good at generating a lot of information. This is because rather than a single estimate you see the distribution of estimates (remember that the Bayesian paradigm believes the parameter to be random =&gt; it has a distribution)</p>
<p>Let’s talk about some of the information: $results mode.N/mean.N/median.N : the mode/mean / median estimate $results L/UCI.N: A 95% percent interval estimate for the richness The picture at the bottom: The distribution of estimates</p>
</div>
<div id="estimating-alpha-and-beta-diversity" class="section level2">
<h2>Estimating alpha and beta diversity</h2>
<p>The above discussion focused exclusively on richness. Check out <code>github.com/adw96/DivNet</code> for alpha and beta diversity tutorials!</p>
</div>
<div id="modelling-alpha-diversity" class="section level2">
<h2>Modelling alpha diversity</h2>
<p>See the vignette <em>Introduction to hypothesis testing for diversity</em>.</p>
<!-- TODO: Fix this to use DivNet -->
<!-- Let's do some comparisons across samples... accounting for variability of course! -->
<!-- We're going to do this procedure for shannon evenness, and estimate it using the plug-in estimate. This is not meant to imply that you should be interested in Shannon! Just that some people are. -->
<!-- Feel free to substitute in whatever alpha diversity/evenness/richness procedure you're interested in! -->
<!-- To do this we will start by iterating on Shannon on every one of our samples. It may take a minute or two to run. Feel like a stretch? Go ahead! -->
<!-- This section may take a while. Do you know if your neighbour likes bagels? Would they order a croissant over a bagel? Now is a great time to find out! -->
<!-- ```{r} -->
<!-- estimates_shannon <- matrix(NA,nrow=dim(otu_data)[2],ncol=4) -->
<!-- rownames(estimates_shannon) <- colnames(otu_data) -->
<!-- colnames(estimates_shannon) <- c("shannon_est","shannon_seest","shannon_lcb","shannon_ucb") -->
<!-- for (i in 1:dim(otu_data)[2]) { -->
<!--   #resample_estimate(otu_data[,i], shannon, my_sample_size = ns) -->
<!--   samples <- replicate(500, resample_estimate(otu_data[,i], shannon, my_sample_size = ns)) -->
<!--   estimates_shannon[i,1] <- mean(samples) -->
<!--   estimates_shannon[i,2] <- sd(samples) -->
<!--   estimates_shannon[i,3:4] <- quantile(samples, c(0.025, 0.975)) -->
<!-- } -->
<!-- ``` -->
<!-- Here gives us our estimates and standard errors so we can have a look estimates_shannon[,1:2] We can even (normal-ish) plot intervals. The x-axis is just against the enumeration of the lakes. It is not meaningful. -->
<!-- The following plotting command may be different to ones you have seen before. It's a really quick way of visualizing the error in your samples and quickly spotting outliers. NOTE: Outliers have SMALL LINES, which means high precision, and are generally far away from points near them. -->
<!-- ```{r} -->
<!-- betta_pic(estimates_shannon[,1], estimates_shannon[,2]) -->
<!-- ``` -->
<!-- No obvious outliers here. -->
<!-- Lets look at the effect of summer samples -->
<!-- ```{r} -->
<!-- col_by_seasons <- ifelse(meta_data$Period=="Autum","black",ifelse(meta_data$Period=="Spring","pink","red")) -->
<!-- betta_pic(estimates_shannon[,1], estimates_shannon[,2], mycol = col_by_seasons) -->
<!-- legend("bottom",c("Spring","Summer","Autumn"),col=c("pink","red","black"),cex=0.8,lwd=3,box.col=F) -->
<!-- ``` -->
<!-- Don't forget that because we are plotting diversity *estimates*, we need to plot *lines* (i.e. confidence intervals) not points (point estimates). That's very important. -->
<!-- We're now going to create our "design" matrix, a.k.a. "X matrix." To do this we're going to cheat a little. We're going to use an existing R method, lm, to save us the hassle. We are going to investigate the effect of temperature and site -->
<!-- ```{r} -->
<!-- covar_matrix <- model.matrix(lm(rnorm(dim(meta_data)[1])~(meta_data$Site)*(meta_data$Period))) -->
<!-- head(covar_matrix) -->
<!-- colnames(covar_matrix) <- c("Int", "SiteP", "Spring", "Summer", "SitePSpring", "SitePSummer") -->
<!-- ``` -->
<!-- Details (skip if uninterested): lm(y~x+z) is a function that fits a regression line to y using the variables x and z. It has a very nice interface that saves you doing the hard work (aka "math") to create your design matrix. The function we are going to use has no such nice interface. For that reason, we steal the design matrix out of lm()'s implementation. lm(y~x*z) looks at interactions. In this case, we are seeing if the evenness trend as a function of temperature changes depending on the site. -->
<!-- Easter egg: if you can put your own data (from your own research) in the *exact* same form as the above example, you don't need to understand what happens below. You can just copy it :) Hint: The biggest problem you may have in implementing the above is the ordering of the data and the metadata. The following: -->
<!-- ```{r} -->
<!-- colnames(otu_data)==rownames(meta_data) -->
<!-- ``` -->
<!-- being true in every spot is a necessary but not sufficient condition for the following to work properly. -->
<!-- ##MODEL SPECIES RICHNESS, TEST SIGNIFICANCE, INTERPRET RESULTS -->
<!-- Let's go ahead and try to fit our model and take a look at the results -->
<!-- ```{r} -->
<!-- results <- betta(estimates_shannon[,1],estimates_shannon[,2],covar_matrix) -->
<!-- results$table -->
<!-- ``` -->
<!-- Interpretation is idential to regression. -->
<!-- Here are some things to quickly note: -->
<!-- Firstly, significance of Spring means that the average Shannon diversity of the Spring samples is significantly higher than non-Spring AT SITE L. It's more by 0.40 on average. -->
<!-- The non-signif of the SiteP variables means there is no significant difference between Sites P and L, in both summer and not... AFTER ACCOUNTING FOR  ESTIMATION ERROR! -->
<!-- Notice that a regression on the Shannon estimates notes more evidence against the "site has no effect" null: -->
<!-- ```{r} -->
<!-- summary(lm(estimates_shannon[,1] ~ meta_data$Site*(meta_data$Period=="Summ")))$coef[,c(1,4)] -->
<!-- ``` -->
<!-- Not such a big deal in this case, but may be with more, marginal results/more variables. -->
<!-- You should always use betta() when modelling and doing inference on functions of your OTU table! -->
<!-- sigsq_u (in full results output) being significant means there is still *heterogeneity* in the lakes. "Not all lakes have the same Shannon diversity even after accounting for season & site." (microscale heterogeneity, pH, chemical factors, depth...?) -->
<!-- If you are unfamiliar with regression analysis, we would recommend taking an introductory course in regression analysis. You will not regret it (after some period of time)! -->
<!-- Congratulations! You have finished the first tutorial! -->
<!-- An important note: I'm not pushing Shannon. You can repeat all of the above analysis with your own favourite index. Suppose I am more interested in Simpson, or inverse Simpson, or Shannon adjusted for population size. Here is how I would do this: -->
<!-- Define a function to take otu columns and estimate the Simpson index using the plug-in estimate -->
<!-- ```{r} -->
<!-- simpson  <-  function(data) { -->
<!--   data <- data/sum(data) -->
<!--   sum(data^2) -->
<!-- } -->
<!-- ``` -->
<!-- Exercise: define a function to calculate the inverse of the plug-in Simpson index  estimate -->
<!-- To estimate the bootstrap mean and standard error of the simpson index, we do the following -->
<!-- ```{r} -->
<!-- simpson_resamples <- replicate(100, resample_estimate(otu_data[,1], simpson)) -->
<!-- hist(simpson_resamples) -->
<!-- mean(simpson_resamples) -->
<!-- sd(simpson_resamples) -->
<!-- ``` -->
<!-- This is just for the first column. You would do this for every sample (in a loop), then use these as inputs to betta. -->
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
